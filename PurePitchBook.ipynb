{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip uninstall keras -y\n",
    "# %pip install keras==3.6.0\n",
    "# %pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDx2foFQV_rl"
   },
   "outputs": [],
   "source": [
    "%pip install keras==3.6.0\n",
    "%pip install tensorflow\n",
    "%pip install pandas\n",
    "%pip install seaborn\n",
    "%pip install scikit-learn\n",
    "%pip install pretty_midi\n",
    "%pip install music21\n",
    "%pip install torch\n",
    "%pip install torcheval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "executionInfo": {
     "elapsed": 8559,
     "status": "ok",
     "timestamp": 1729777067292,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "TSjP-8ufWRa3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import pathlib\n",
    "import collections\n",
    "import datetime\n",
    "import glob\n",
    "import music21\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torcheval.metrics.text import Perplexity\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Gen using LSTM model\n",
    "\n",
    "This project will use a 4 layer keras LSTM model to predict notes based on training from a famous jazz recording captures that were converted to midi.\n",
    "\n",
    "The notebook has 3 main sections.\n",
    "* Training Data Preparation\n",
    "* Model Definition and fit\n",
    "* Predictions based on sample input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "Some conversion and database i/o functions were split into a separate python file to help readability of this notebook.  This are loaded here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib  # allows reload of my_functions\n",
    "import my_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(my_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell defines global constants that are used throughout the notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global things used throughout the notebook\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# length of trainig sequences\n",
    "seq_length = 20\n",
    "\n",
    "# Size of pitch vocab\n",
    "vocab_size = 128\n",
    "\n",
    "# Keys that will get extracted into the training set. This are the inputs to the model!\n",
    "key_order = ['pitch', 'step', 'duration', 'tempo', 'instrument_num', 'key_num']\n",
    "\n",
    "# Songs to exclude from training\n",
    "#skip_list = random.sample(range(1, 456), 16)\n",
    "skip_list = [ 311, 50, 66, 283, 95, 303, 284, 238, 297, 276, 416, 254, 346, 161, 125, 362]\n",
    "\n",
    "# Skipped songs to be used for Validation\n",
    "val_list = skip_list[:10]\n",
    "\n",
    "# Skipped songs to be used for Testing\n",
    "test_list = skip_list[10:]\n",
    "\n",
    "\n",
    "model_save_file = 'PurePitchSave.keras'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell will load training data using a SQL query and calculate some differential values\n",
    "\n",
    "Training data is loaded into a Dataframe.  Many fields are just extracted from the wjazzd.db sqlite\n",
    "database. Others are calculated on the dataframe once it is created.\n",
    "\n",
    "Fields for each note from the database are created joining the tables \"melody\" and \"solo_info\"\n",
    "* pitch - from melody.pitch midi note value (0-127)\n",
    "* pitch_norm - from melody.pitch / 128 as pitch_norm  Normalized pitch.  (not used)\n",
    "* start - from melody.onset as start  Start time of the note\n",
    "* end - from melody.onset + melody.duration as end  End time of the note\n",
    "* duration - from melody.duration duration of the note in seconds\n",
    "* instrument - from solo_info.instrument string representing of the instrument used ie \"cl\" (clarinet)\n",
    "* key - solo_info.key string value reprensenting the musical key ie: \"Bb-maj\"\n",
    "* style - from solo_info.style string representing the song genre ie: \"COOL\" or \"POSTBOP\"\n",
    "* tempo - from solo_info.avgtempo as tempo reprensented in BPM\n",
    "* feel - from solo_info.rhythmfeel as feel string represening rhythmic feel ie \"SWING\" or \"LATIN\" \n",
    "* title - from solo_info.title,\n",
    "* performer = from solo_info.performer string of the name of the artist on the solo\n",
    "\n",
    "Once the data is loaded, these additional fields are create\n",
    "* step - time between the previous note and this note\n",
    "* interval - pitch difference between\n",
    "* contour - interval abstraction based on my_functions.contour()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads up all the notes in the dataset\n",
    "pitchInst = my_functions.extract_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn to alpha numeric lables into numbers for training input\n",
    "* instrument_num maps to the type of instrument used in the solo\n",
    "* key_num maps to the musical key that the tune was in (Bb-maj for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "pitchInst['instrument_num'] = le.fit_transform(pitchInst['instrument']).astype(float)\n",
    "pitchInst['key_num'] = le.fit_transform(pitchInst['key']).astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim off extraneous notes from the training data and skip songs\n",
    "\n",
    "For the model to train correctly, the training set must be an integral multiple of seq_length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_notes, train_notes = my_functions.trim_data_sequence(\n",
    "        pitchInst, \n",
    "        skip_list, \n",
    "        seq_length,\n",
    "        key_order)\n",
    "\n",
    "notes_ds = tf.data.Dataset.from_tensor_slices(train_notes)\n",
    "notes_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_length, val_notes = my_functions.select_data_sequences(pitchInst, \n",
    "        val_list, \n",
    "        seq_length,\n",
    "        key_order)\n",
    "\n",
    "val_notes_ds = tf.data.Dataset.from_tensor_slices(val_notes)\n",
    "val_notes_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_seq_ds = my_functions.create_sequences(val_notes_ds, key_order, seq_length, vocab_size)\n",
    "val_seq_ds.__len__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = val_length #  - seq_length  # the number of items in the dataset\n",
    "val_ds = (val_seq_ds\n",
    "            .shuffle(buffer_size)\n",
    "            .batch(batch_size, drop_remainder=True)\n",
    "            .cache()\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1729777317788,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "vvUPy1h-pgwL",
    "outputId": "772d3214-91f8-4e23-f674-9c0c29546add"
   },
   "outputs": [],
   "source": [
    "seq_ds = my_functions.create_sequences(notes_ds, key_order, seq_length, vocab_size)\n",
    "seq_ds.__len__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1729777346217,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "FAdNRRuhxD2b"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = n_notes #  - seq_length  # the number of items in the dataset\n",
    "train_ds = (seq_ds\n",
    "            .shuffle(buffer_size)\n",
    "            .batch(batch_size, drop_remainder=True)\n",
    "            .cache()\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "\n",
    "If the model can be restored from the saved file, use that.  Otherwise, build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1729777385441,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "yaHEn45JyExj",
    "outputId": "9486ced4-b5cb-4403-a0d6-73293f0d06de"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "  model = tf.keras.models.load_model(model_save_file)\n",
    "except:\n",
    "  # definition for the inputs.  Note how num of inputs is realted to size of key_order global\n",
    "  input_shape = (seq_length, len(key_order))\n",
    "  learning_rate = 0.010\n",
    "\n",
    "  #input layer\n",
    "  inputs = tf.keras.Input(input_shape)\n",
    "  #hidden layers\n",
    "  x = tf.keras.layers.LSTM(128, return_sequences=True)(inputs)\n",
    "  x = tf.keras.layers.Dropout(0.20, seed=seed)(x) #dropout layer\n",
    "  x = tf.keras.layers.LSTM(16, return_sequences=True)(x)\n",
    "  x = tf.keras.layers.Dropout(0.20, seed=seed)(x) #dropout layer\n",
    "  x = tf.keras.layers.LSTM(16, return_sequences=False)(x) #last layer to outputs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  outputs = {\n",
    "    'pitch': tf.keras.layers.Dense(128, name='pitch')(x),\n",
    "    'step': tf.keras.layers.Dense(1, name='step')(x),\n",
    "    'duration': tf.keras.layers.Dense(1, name='duration')(x),\n",
    "  }\n",
    "\n",
    "  model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "  loss = {\n",
    "        'pitch':tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        'step': \"mean_squared_error\",\n",
    "        'duration': \"mean_squared_error\",\n",
    "  }\n",
    "\n",
    "  # loss = {\n",
    "  #       'pitch':tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  #       'step': mse_with_positive_pressure,\n",
    "  #       'duration': mse_with_positive_pressure,\n",
    "  # }\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "  model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "  model.summary()\n",
    "  # these are the three outputs of the model\n",
    "\n",
    "  model.compile(\n",
    "      loss=loss,\n",
    "      loss_weights={\n",
    "          'pitch': 1.0,\n",
    "          'step': 1.0,\n",
    "          'duration':1.0,\n",
    "      },\n",
    "      optimizer=optimizer,\n",
    "  )\n",
    "\n",
    "  model.evaluate(train_ds, return_dict=True)\n",
    "  callbacks = [\n",
    "      tf.keras.callbacks.ModelCheckpoint(\n",
    "          filepath='./training_checkpoints/ckpt_{epoch}.weights.h5',\n",
    "          save_weights_only=True),\n",
    "      tf.keras.callbacks.EarlyStopping(\n",
    "          monitor='loss',\n",
    "          min_delta=0.001,\n",
    "          patience=5,\n",
    "          verbose=1,\n",
    "          start_from_epoch=2,\n",
    "          restore_best_weights=True),\n",
    "  ]\n",
    "  \n",
    "  epochs = 30\n",
    "\n",
    "  history = model.fit(\n",
    "      train_ds,\n",
    "      epochs=epochs,\n",
    "      callbacks=callbacks,\n",
    "      validation_data=val_ds,\n",
    "  )\n",
    "  model.save(model_save_file)\n",
    "  np.save('history_purepitch.npy', history.history, allow_pickle=True) # save training data for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_history = np.load('history_purepitch.npy', allow_pickle=True) # save training data for later\n",
    "loaded_history.item(0)['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIMee7mLBQ5z"
   },
   "outputs": [],
   "source": [
    "def predict_next_note(\n",
    "    notes: np.ndarray,\n",
    "    model: tf.keras.Model,\n",
    "    temperature: float = 1.0) -> tuple[int, float, float]:\n",
    "  \"\"\"Generates a note as a tuple of (pitch, step, duration), using a trained sequence model.\"\"\"\n",
    "\n",
    "  assert temperature > 0\n",
    "\n",
    "  # Add batch dimension\n",
    "  inputs = tf.expand_dims(notes, 0)\n",
    "\n",
    "  predictions = model.predict(inputs)\n",
    "  pitch_logits = predictions['pitch']\n",
    "  step = predictions['step']\n",
    "  duration = predictions['duration']\n",
    "\n",
    "  pitch_logits /= temperature \n",
    "  pitch = tf.random.categorical(pitch_logits, num_samples=1) \n",
    "  pitch = tf.squeeze(pitch, axis=-1) \n",
    "  duration = tf.squeeze(duration, axis=-1)\n",
    "  step = tf.squeeze(step, axis=-1)\n",
    "\n",
    "  # `step` and `duration` values should be non-negative\n",
    "\n",
    "  step = tf.maximum(0, step)\n",
    "  duration = tf.maximum(0, duration)\n",
    "  \n",
    "\n",
    "  return int(pitch), float(step), float(duration), pitch_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_unit_perplexity(logits, target): \n",
    "  metric=Perplexity()\n",
    "  input = torch.tensor(logits)\n",
    "  target_tens = torch.tensor([target])\n",
    "  metric.update(input, target_tens)\n",
    "  return metric.compute()\n",
    "\n",
    "#calc_unit_perplexity(agg_logits[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 1.0\n",
    "num_predictions = seq_length\n",
    "\n",
    "def note_loop(song):\n",
    "  test_notes = pitchInst[pitchInst['melid'] == song].reset_index()\n",
    "  sample_notes = np.stack([test_notes[key] for key in key_order], axis=1)\n",
    "\n",
    "  input_notes = sample_notes[:seq_length]\n",
    "\n",
    "  # These are common fields to the entire test set\n",
    "  tempo = test_notes['tempo'].iloc[seq_length]\n",
    "  inst = test_notes['instrument_num'].iloc[seq_length]\n",
    "  key = test_notes['key_num'].iloc[seq_length]\n",
    "  title = test_notes['title'].iloc[seq_length]\n",
    "  performer = test_notes['performer'].iloc[seq_length]\n",
    "  instrument_name = test_notes['instrument'].iloc[seq_length]\n",
    "\n",
    "  generated_notes = []\n",
    "  # this is the last start time of the prompt set\n",
    "  prev_start = test_notes['start'][seq_length]\n",
    "  agg_logits = []\n",
    "  pplex = []\n",
    "  #contour = 0  #initial contour should be last contour of input sequence\n",
    "  for i in range(num_predictions): #THERE ARE PROBLEMS HERE\n",
    "    pitch, step, duration, pitch_logits = predict_next_note(input_notes, model, temperature)\n",
    "    start = prev_start\n",
    "    end = start + duration\n",
    "    interval = input_notes[-1][0] - pitch\n",
    "    contour = my_functions.contour(interval)\n",
    "    agg_logits.append(pitch_logits)\n",
    "    target_note = test_notes['pitch'].iloc[seq_length + i].astype(int)\n",
    "    pplex.append(calc_unit_perplexity([pitch_logits], [target_note]))\n",
    "    # TODO:\n",
    "    # This line has to change when you change the inputs to the model.  The input_note\n",
    "    # that is getting appended to input notes needs to have the correct number and order of \n",
    "    # fields cause it is gonna get fed back into the model.predict function\n",
    "    # input_note = (pitch, step, duration)\n",
    "    input_note = (pitch, step, duration, tempo, inst, key)\n",
    "    generated_notes.append((*input_note, start, end))\n",
    "    input_notes = np.delete(input_notes, 0, axis=0)\n",
    "    input_notes = np.append(input_notes , np.expand_dims(input_note, 0), axis=0) \n",
    "    prev_start = start + step\n",
    "    \n",
    "  generated_notes = pd.DataFrame(\n",
    "      generated_notes, columns=(*key_order, 'start', 'end'))\n",
    "\n",
    "  start_df = test_notes[:seq_length].drop(['interval'], axis=1)\n",
    "  \n",
    "\n",
    "  # string together the first training data and the generated notes\n",
    "  full_sequence = pd.concat([start_df, generated_notes], ignore_index=True)\n",
    "\n",
    "  example_file = f\"MixedModel-Song-{song}_seq-{seq_length}-{performer}-{title}.midi\"  # adds a prefix to the sample filename\n",
    "  my_functions.notes_to_midi(full_sequence[['pitch', 'step', 'duration', 'tempo']], out_file=example_file, instrument_name='Acoustic Grand Piano')\n",
    "\n",
    "  return test_notes[:len(full_sequence)], full_sequence, generated_notes, title, performer, agg_logits, pplex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_list = test_list\n",
    "#run_list = [41, 42, 74, 75, 89]\n",
    "targets, full_sequence, generated_notes, title, performer, agg_logits, pplex = note_loop(run_list[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot pplex as a line graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pplex, marker='o', linestyle='-', color='b')\n",
    "plt.title('Perplexity Over Time')\n",
    "plt.xlabel('Prediction Step')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_perplexity(agg_logits, target, num_predictions):\n",
    "  x = target['pitch'].tail(num_predictions).astype(int).to_numpy()\n",
    "  np.array_split(x, num_predictions)\n",
    "  metric=Perplexity()\n",
    "  input = torch.tensor(agg_logits)\n",
    "  target_tens = torch.tensor(np.array_split(x, num_predictions))\n",
    "  metric.update(input, target_tens)\n",
    "  return metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_perplexity(agg_logits, targets, num_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_functions.plot_notes(full_sequence, seq_length ,heading=f'Predictions: {title}-{performer}')\n",
    "my_functions.plot_notes(targets, seq_length, heading=f'Actual: {title}-{performer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_functions.plot_distributions(generated_notes, title=\"Generated Notes Distribution\")\n",
    "my_functions.plot_distributions(targets, title=\"Target Data Notes\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMbAUZAKMT3LWx3S3x1qvHL",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
